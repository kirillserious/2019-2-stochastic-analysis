\section{Задание №3}

\begin{enumerate}
        \item Построить датчик экспоненциального распределения. 
        Проверить для данного распределения свойство отсутствия памяти. Пусть $X_1,\,X_2,\,\ldots,\,X_n$ независимо распределенные случайные величины с параметрами $\lambda_1,\,\lambda_2,\,\ldots,\,\lambda_n$ соответственно. 
        Найти распределение случайной величины $Y = \min\{\,X_1,\,X_2,\,\ldots,\,X_n\,\}$.
        \item На основе датчика экспоненциального распределения построить датчик пуассоновского распределения.
        \item Построить датчик пуассоновского распределения как предел биномеального распределения.
        С помощью критерия хи-квадрат Пирсона убедиться, что получен датчик распределения Пуассона.
        \item Построить датчик стандартного распределения методом моделирования случайных величин парами с переходом в полярные координаты. Проверить при помощи t-критерия Стьюдента равенство математических ожиданий, а при помощи критерия Фишера --- равенство дисперсий.
\end{enumerate}

\subsection{Задача №1}

\begin{definition}
        Случайная величина $X$ имеет экспоненциальное распределение с параметром $\lambda > 0$, если ее функция распределения имеет вид
$$
        F_X(x) = 
        \begin{cases}
                1 - e^{-\lambda x},& \mbox{при $x \geqslant 0$,} \\
                0, & \mbox{при $x < 0$.}
        \end{cases}
$$
        Будем обозначать такие случайные величины
$$
        X \sim \mbox{Exp}(\lambda).
$$
\end{definition}

Для того чтобы построить датчик экспоненциально распределенной с параметром $\lambda$ случайной величины $X$, воспользуемся доказанной ранее теоремой~\ref{th:th2-1}. Получается, что такую случайную величину можно представить в виде:
$$
        X =
        F_x^{-1}(\xi) =
        -\frac{1}{\lambda}\ln(1 - \xi),
$$
где $\xi$~--- равномерно распределенная на отрезке $[0,\,1]$ случайная величина.

\begin{assertion}[Свойство отсутствия памяти]
        Пусть $X\sim\mbox{Exp\,}(\lambda)$, тогда для любых $t \neq 0$ и $s$ справедливо:
$$
        \p(X\geqslant s+t\,|\,X\geqslant t) =
        \p(X \geqslant s).
$$
\end{assertion}

\begin{proof}
        Рассмотрим левую часть равенства:
$$
        \p(X \geqslant s + t\,|\,X\geqslant t) =
        \frac{\p(X \geqslant s + t,\,X\geqslant t)}{\p{X\geqslant t}} =
        \frac{\p(X \geqslant s + t)}{\p(X\geqslant t)}.
$$
Таким образом получаем, утверждение эквивалентно тому, что
$$
        \p(X\geqslant s+t) = 
        \p(X\geqslant t)\p(X\geqslant s).
$$
Из определения функции распределения $F_X(t) = \p(X < t) = 1 - \p(X \geqslant t)$ получаем, что
$$
        e^{-\lambda(s+t)} = e^{-\lambda s}e^{-\lambda t}.
$$
Последнее равенство точно верно. Таким образом, утверждение доказано.
\end{proof}

Рассмотрим теперь случайную величину $Y = \min\{\,X_1,\,X_2,\,\ldots,\,X_n\,\}$, где $X_i, i = \overline{1,\,n}$ есть независимо распределенные экспоненциальные случайные величины с параметрами $\lambda_1,\,\lambda_2,\,\ldots,\,\lambda_n$ соответственно, и найдем её функцию распределения:
\begin{multline*}
        F_Y(x) =
        \p(Y < x) = 
        \p (\min\limits_{i = \overline{1,\,n}} X_i < x) =
        1 - \p (\min\limits_{i = \overline{1,\,n}} X_i \geqslant x) =
        \\
        = 1 - \p(X_1 \geqslant x,\,X_2 \geqslant x,\,\ldots,\,X_n \geqslant x) =
        1 - \prod_{i = 1}^{n} \p (X_i \geqslant x) = 
        1 - \prod_{i = 1}^n(1 - F_{X_i}(x)).
\end{multline*}
Таким образом функция распределения случайной величины $Y$ представима в виде
$$
        F_Y(x) = 1 - \prod_{i = 1}^n (1 - 1 + e^{\lambda_i x}) =
        1 - \prod_{i = 1}^n e^{\lambda_i x} = 1 - e^{(\lambda_1 + \lambda_2 + \ldots + \lambda_n)x}.
$$
Получается, что заданная случайная величина $Y$ имеет экспоненциальное распределение с параметром $\lambda = \lambda_1 + \lambda_2 + \ldots + \lambda_n$.

\subsection{Задача №2}

\begin{definition}
        Случайная величина $X$ имеет распределение Пуассона \texttt{дописать}.
\end{definition}

Для построения датчика Пуассоновской случайной величины докажем вспомогательную теорему.
\begin{theorem}[О распределении суммы экспоненциальных случайных величин]
\label{th:2-2-1}
        Пусть $S_n = \sum_{i=1}^n \xi_i$, где $\xi_i\sim\mbox{Exp}(\lambda)$, $i = \overline{1,\,n}$.
        Тогда
$$
        F_{S_n}(x) = 1 - e^{-\lambda x}\sum_{k = 0}^{n-1} \frac{\lambda^k x^k}{k!}.
$$
\end{theorem}
\begin{proof}
        Для доказательства достаточно показать, что случайная величина~$S_n$ имеет плотность распределения, равную
$$
        \rho_{S_n}(x) = e^{-\lambda x}\frac{\lambda^{n}x^{n-1}}{(n-1)!},\quad x\geqslant 0.
$$
Докажем это методом математической индукции.
База индукции очевидна.
Теперь пусть для шага $n$ выполнена предыдущая формула.
Воспользуемся формулой свертки плотностей распределений для нахождения $\rho_{S_{n+1}}$
$$
        \rho_{S_{n+1}}(x)
        =
        \int_0^x \rho_{S_1}(x - t)\cdot\rho_{S_n}(t)\,dt
        =
        \frac{\lambda^{n+1}}{(n-1)!}e^{-\lambda x}\int_0^x (x-t)^{n-1}\,dt
        =
        \frac{\lambda^{n+1}}{(n-1)!} e^{-\lambda x}\frac{x^n}{n}.
$$
Теорема доказана.

\end{proof}

Пусть $t > 0$. Рассмотрим независимые случайные величины $\{\xi_k\}_{k \geqslant 1}$, име.щие показательное распределение с параметром $\lambda$. Как и в предыдущей теореме, положим $S_n = \sum_{k=1}^n \xi_k$. Наконец, обозначим $X = \max\{\,n\geqslant 0\;|\;S_n < t\}$, полагая $S_0 = 0$. Докажем теперь, что $X\sim\mbox{Pois}(\lambda t)$.

Для этого найдем вероятность того, что $X = n$. При $n = 0$
$$
        \p (X = n) = \p (\xi_1 \geqslant t) = e^{\lambda t}.
$$
При $n > 0$, поскольку $\xi_k \geqslant 0$, то согласно теореме \ref{th:2-2-1}
\begin{multline*}
        \p (X = n) 
        =
        \p (S_n < t,\, S_{n+1} \geqslant t)
        =
        \p(S_n < t) - \p(S_n < t,\,S_{n+1} < t)
        = \\ =
        \p(S_n < t) - \p(S_{n+1} < t)
        =
        F_{S_n}(t) - F_{S_{n-1}}(t)
        =
        \frac{\lambda^n t^n}{n!}e^{-\lambda t}.
\end{multline*}

Таким образом мы получали способ построения пуассоновской случайной величины. Нужно просто брать показательные случайные величины с параметром $\lambda = 1$ и смотреть сумма скольки первых из них меньше параметра пуассоновского распределения.

\subsection{Задача №3}
Биномиальное распределение сходится к распределению Пуассона, так как число испытаний уходит в бесконечность, в то время как произведение $np$ остается фиксированным или, по крайней мере, $p$ стремится к нулю. Поэтому распределение Пуассона с параметром $\lambda = np$ можно использовать как приближение к $\mbox{Bin }(n,\,p)$ биномиального распределения, если $n$ достаточно велико, а $p$ достаточно мало. Согласно двум эмпирическим правилам, это приближение хорошо, если $n \geqslant 20$ и $p \leqslant 0,05$ или если $n \geqslant 100$ и $np \leqslant 10$. Подробнее см. \cite{counts_control_charts}. Относительно точности приближения Пуассона см. \cite{novak}[Chapter 4].

Таким образом смоделируем случайную величину таким образом
$$
        \mbox{Pois}(\lambda) \approx \mbox{Bin}(n,\,p), \mbox{где }n > 20\lambda.
$$

\subsection{Задача №4}
\begin{definition}
        \texttt{Нормалное распределение --- это ...}
\end{definition}

Рассмотрим случайную величину $Z = \sqrt{2\xi}\sin\eta$, где $\xi\sim\mbox{Exp}\,(1)$, $\eta\sim\mbox{U}[0,2\,\pi] \sim 2\pi\mbox{U}[0,\,1]$. Тогда
\begin{multline*}
        \p(Z < x)
        =
        \p(\sqrt{2\xi}\sin\eta < x)
        =
        \iint\limits_{\{\,(\xi,\,\eta)\,|\,\sqrt{2\xi}\sin\eta<x\,\}} \frac{e^{-\xi}}{2\pi}\,d\xi d\eta
        =
        \left\{\,\xi = \frac{\psi^2}{2}\,\right\}
        = \\ =
        \iint\limits_{\{\,(\psi,\,\eta)\,|\,\psi\sin\eta<x\,\}} \frac{e^{-\frac{\psi^2}{2}}}{2\pi}\psi\,d\psi d\eta
        =
        \{\,X = \psi\cos\eta,\,Y = \psi\sin\eta\,\}
        = \\ =
        \iint\limits_{\{\,(X,\,Y)\,|\,Y < x\,\}} \frac{e^{-\frac{X^2}{2}}e^{-\frac{Y^2}{2}}}{2\pi}\,dXdY
        =
        \int\limits_{-\infty}^{+\infty}\frac{e^{-\frac{X^2}{2}}}{\sqrt{2\pi}}\,dX \int\limits_{-\infty}^{x} \frac{e^{-\frac{Y^2}{2}}}{\sqrt{2\pi}}\,dY
        =
        \int\limits_{-\infty}^{x}\frac{e^{-\frac{Y^2}{2}}}{\sqrt{2\pi}}\,dy.
\end{multline*}
Таким образом случайная величина $Z$ имеет стандартное нормальное распределение.
\clearpage
\begin{figure}[t]
        \includegraphics[width=0.5\linewidth]{task_03/exp2-1000.eps}
        \includegraphics[width=0.5\linewidth]{task_03/exp2-100000.eps}
        \caption{Гистограмма экспоненциального распределения случайной величины с параметром $\lambda = 2$ при $10^3$~(слева) и $10^5$~(справа) испытаний.}
\end{figure}
\begin{figure}[h]
        \includegraphics[width=\linewidth]{task_03/mem2-1000-1.eps}
        \caption{Гистограмма экспоненциального распределения, демонстрирующая его свойство отсутствия памяти. Здесь задан параметр распределения $\lambda = \frac{3}{2}$, а также <<сдвиг>> $m = 1$. Проведено $10^3$ испытаний.}
\end{figure}
\begin{figure}[h]
        \includegraphics[width=\linewidth]{task_03/min-01-10-10000.eps}
        \caption{Гистограмма распределения случайной величины $Y = \min_{i = \overline{1, n}} X_i$. Здесь $\lambda_1 = \lambda_2 = \ldots = \lambda_n = \frac{1}{10}$, $n = 10$. Число испытаний $10^4$.}
\end{figure}
\begin{figure}[h]
        \includegraphics[width=0.5\linewidth]{task_03/pois2-10000.eps}
        \includegraphics[width=0.5\linewidth]{task_03/pois10-10000.eps}
        \caption{Гистограмма распределения Пуассона случайной величины с параметром $\lambda = 2$~(слева) и $\lambda = 10$~(справа) при $10^4$~испытаний.}
\end{figure}